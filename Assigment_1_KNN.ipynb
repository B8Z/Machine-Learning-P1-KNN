{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scipy.spatial library to get distance methods\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#Method to get the euclidean distance between two points\n",
    "def euclidean(first_point, second_point):\n",
    "    return distance.euclidean(first_point, second_point)\n",
    "\n",
    "def mahalanobis(point1, point2, trainingSet):\n",
    "    VI = np.linalg.inv(covMatrix)\n",
    "    return distance.mahalanobis(point1, point2, VI)\n",
    "\n",
    "#Method to get the cosine distance between two points\n",
    "def cosine(first_point, second_point):\n",
    "    return distance.cosine(first_point, second_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution average - A data: [1.03719019 1.03763461]\n"
     ]
    }
   ],
   "source": [
    "#Import numpy as np for mathematical manipulation, used throughout program\n",
    "import numpy as np\n",
    "\n",
    "#Generate class A data\n",
    "N = 500\n",
    "mean = [1,1]\n",
    "cov = [[0.3, 0.2],[0.2, 0.2]]\n",
    "A_data = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "Class_a = []\n",
    "for i in range(len(A_data)):\n",
    "    Class_a.append(np.append(A_data[i],[0]))\n",
    "Class_a = np.asarray(Class_a)\n",
    "\n",
    "total = [0,0]\n",
    "for i in A_data:\n",
    "    total = total + i\n",
    "average = total / len(A_data)\n",
    "print(\"distribution average - A data:\", average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution average - B data: [2.98434661 4.01680581]\n"
     ]
    }
   ],
   "source": [
    "#Generate class B data\n",
    "N = 500\n",
    "mean = [3,4]\n",
    "cov = [[0.3, 0],[0, 0.2]]\n",
    "B_data = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "Class_b = []\n",
    "for i in range(len(B_data)):\n",
    "    Class_b.append(np.append(B_data[i],[1]))\n",
    "Class_b = np.asarray(Class_b)\n",
    "\n",
    "total = [0,0]\n",
    "for i in B_data:\n",
    "    total = total + i\n",
    "average = total / len(B_data)\n",
    "print(\"distribution average - B data:\", average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution average - unknown data: [2.06104643 2.97067293]\n"
     ]
    }
   ],
   "source": [
    "#Generate unknown data\n",
    "N = 300\n",
    "mean = [2,3]\n",
    "cov = [[0.3, 0],[0, 0.2]]\n",
    "unknown_data = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "total = [0,0]\n",
    "for i in unknown_data:\n",
    "    total = total + i\n",
    "average = total / len(unknown_data)\n",
    "print(\"distribution average - unknown data:\", average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate using k=1...\n",
      "Evaluate using k=30...\n",
      "Predicted 1 samples length:  65\n",
      "Predicted 2 samples length:  235\n",
      "Predicted 1 samples length:  24\n",
      "Predicted 2 samples length:  276\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Set random seed so it is testable\n",
    "np.random.seed(1) \n",
    "\n",
    "#Count the neighbors\n",
    "def count_neighbors(data):\n",
    "    neighbor_count = [0,0]\n",
    "    for n in data:\n",
    "        if n[2] == 0:\n",
    "            neighbor_count[0] = neighbor_count[0] +1\n",
    "        elif n[2] == 1:\n",
    "            neighbor_count[1] = neighbor_count[1] +1\n",
    "    if neighbor_count[0] > neighbor_count[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#Get the knn\n",
    "def k_nearest_neighbor(k, training_data, data_point):\n",
    "    neighbors = deepcopy(training_data[:k])\n",
    "    for i in range(k, len(training_data)):\n",
    "        for j in range(len(neighbors)):\n",
    "            first_distance = distance.euclidean(training_data[i][:2], data_point)\n",
    "            second_distance = distance.euclidean(neighbors[j][:2], data_point)\n",
    "            if first_distance < second_distance:\n",
    "                neighbors[j] = deepcopy(training_data[i])\n",
    "                break\n",
    "    return neighbors\n",
    "    \n",
    "#Evaluate the unknown points\n",
    "def evaluate_data(k, training_data, unknown_data):\n",
    "    classified_data = []\n",
    "    for i in range(len(unknown_data)):\n",
    "        data_point = unknown_data[i]\n",
    "        knn_value = k_nearest_neighbor(k, training_data, data_point)\n",
    "        classified_datapoints = count_neighbors(knn_value)\n",
    "        classified_data.append(np.append(data_point, classified_datapoints))\n",
    "    return np.asarray(classified_data)\n",
    "\n",
    "training_data = np.append(Class_a, Class_b, axis=0)\n",
    "\n",
    "print(\"Evaluate using k=1...\")\n",
    "unknown_k1 = evaluate_data(1, training_data, unknown_data)\n",
    "\n",
    "print(\"Evaluate using k=30...\")\n",
    "unknown_k30 = evaluate_data(30, training_data, unknown_data)\n",
    "\n",
    "def plot_knn(class1,class2, classifiedData, k):\n",
    "    predicted1_samples = []\n",
    "    predicted2_samples = []\n",
    "    for data_point in classifiedData:\n",
    "        if data_point[2] == 0:\n",
    "            predicted1_samples.append(data_point)\n",
    "        else:\n",
    "            predicted2_samples.append(data_point)\n",
    "    predicted1_samples = np.asarray(predicted1_samples)\n",
    "    predicted2_samples = np.asarray(predicted2_samples)\n",
    "    print(\"Predicted 1 samples length: \", len(predicted1_samples))\n",
    "    print(\"Predicted 2 samples length: \", len(predicted2_samples))\n",
    "    fig_output = \"k = \"+str(k)\n",
    "    fig_title = fig_output + \" Euclidean Distance Classification\"\n",
    "    fig = plt.figure()\n",
    "    plt.plot(class1[:, 0], class1[:, 1], 'b.', label='given class a')\n",
    "    plt.plot(class2[:, 0], class2[:, 1], 'r.', label='given class b')\n",
    "    plt.plot(predicted1_samples[:, 0], predicted1_samples[:, 1], 'g*', label='predicted class a')\n",
    "    plt.plot(predicted2_samples[:, 0], predicted2_samples[:, 1], '*', color='orange', label='predicated class b')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-Axis')\n",
    "    plt.title(fig_title)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, lw=0.5)\n",
    "    plt.legend()\n",
    "    fig.savefig(fig_output)\n",
    "\n",
    "plot_knn(Class_a, Class_b, unknown_k1, 1) #Number of folds\n",
    "plot_knn(Class_a, Class_b, unknown_k30, 30) #Number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRIS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "\n",
    "iris_location = 4\n",
    "\n",
    "#Read file and put into a numpy array\n",
    "def read_file(): \n",
    "    data = []\n",
    "    with open(\"iris.data\", \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            classification = row[iris_location]\n",
    "            if(classification == Setosa.string_value):\n",
    "                row[iris_location] = 1\n",
    "            elif(classification == Versicolor.string_value):\n",
    "                row[iris_location] = 2\n",
    "            elif(classification == Virginica.string_value):\n",
    "                row[iris_location] = 3\n",
    "            for i in range(len(row)):\n",
    "                row[i] = float(row[i])\n",
    "            data.append(row)\n",
    "    return np.asarray(data)\n",
    "\n",
    "#Shuffle and randomize the data\n",
    "def shuffle_data(data):\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "#Split testing and training data, ratio of 80/20\n",
    "def split_data(data):\n",
    "    number_datapoints = math.floor(len(data) * 0.20)\n",
    "    split_data_values = np.split(data, [number_datapoints])\n",
    "    return split_data_values\n",
    "\n",
    "#Perform a k-split on the data\n",
    "def k_split(data, k):\n",
    "    k_split_values = np.array_split(data, k)\n",
    "    return k_split_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an iris class to properly track the metrics\n",
    "class iris_class:\n",
    "    def __init__(self):\n",
    "        self.true_positives = 0\n",
    "        self.true_negatives = 0\n",
    "        self.false_positives = 0\n",
    "        self.false_negatives = 0\n",
    "    def accuracy(self):\n",
    "        total = self.true_positives + self.true_negatives + self.false_positives + self.false_negatives\n",
    "        accuracy = (self.true_positives + self.true_negatives) / (total)\n",
    "        return accuracy\n",
    "    def recall(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_negatives)\n",
    "    def precision(self):\n",
    "        return self.true_positives / (self.true_positives + self.false_positives)\n",
    "    def f1score(self):\n",
    "        p = self.true_positives / (self.true_positives + self.false_positives)\n",
    "        r = self.true_positives / (self.true_positives + self.false_negatives)\n",
    "        f1 = 2 * ((p * r) / (p + r))\n",
    "        return f1\n",
    "    def performance(self):\n",
    "        print(\"Iris type: \", self.string_value)\n",
    "        print(\"Accuracy: \",  self.accuracy())\n",
    "        print(\"Recall: \",    self.recall())\n",
    "        print(\"Precision: \", self.precision())\n",
    "        print(\"F1 Score: \",   self.f1score())\n",
    "\n",
    "#Create class for Iris-setosa\n",
    "class Setosa(iris_class):\n",
    "    integer_value = 1\n",
    "    string_value = \"Iris-setosa\"\n",
    "    \n",
    "#Create class for Iris-versicolor\n",
    "class Versicolor(iris_class):\n",
    "    integer_value = 2\n",
    "    string_value = \"Iris-versicolor\"\n",
    "\n",
    "#Create class for Iris-virginica\n",
    "class Virginica(iris_class):\n",
    "    integer_value = 3\n",
    "    string_value = \"Iris-virginica\"\n",
    "    \n",
    "#Create class to store the data\n",
    "class data:\n",
    "    full_dataset = shuffle_data(read_file())\n",
    "    testing_data, training_data = split_data(full_dataset)\n",
    "    data_with_k_split = k_split(training_data, 5) #Number of folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform cross validation on k\n",
    "def crossValidation(k, distance_type):\n",
    "    folds = data.data_with_k_split\n",
    "    for i in range(len(folds)):\n",
    "        testing_data_folds = deepcopy(folds[i])\n",
    "        folds_removed  = np.delete(deepcopy(folds), i, 0)\n",
    "        training_data = np.concatenate(folds_removed)\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(\"------------- Initiate Fold ----------------\")\n",
    "        print(\"--------------------------------------------\")\n",
    "        evaluate(k, training_data, testing_data_folds, distance_type)\n",
    "        print(\"--------------------------------------------\")\n",
    "        print(\"-------------- End Fold\", i, \"--------------\")#Count the neighbors for knn\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "#Count neighbors for knn\n",
    "def count_neighbors_knn(knn):\n",
    "    neighbor_count = [0, 0, 0]\n",
    "    for n in knn:\n",
    "        if n[iris_location] == Versicolor.integer_value:\n",
    "            neighbor_count[1] = neighbor_count[1] + 1\n",
    "        if n[iris_location] == Virginica.integer_value:\n",
    "            neighbor_count[2] = neighbor_count[2] + 1\n",
    "        if n[iris_location] == Setosa.integer_value:\n",
    "            neighbor_count[0] = neighbor_count[0] + 1\n",
    "    if neighbor_count[1] >= neighbor_count[0] and neighbor_count[1] >= neighbor_count[2]:\n",
    "        return Versicolor.integer_value\n",
    "    elif neighbor_count[0] >= neighbor_count[1] and neighbor_count[0] >= neighbor_count[2]:\n",
    "        return Setosa.integer_value\n",
    "    else:\n",
    "        return Virginica.integer_value\n",
    "\n",
    "#Perform knn evaluation\n",
    "def k_nearest_neighbor(k, training_data, data_point, distance_type):\n",
    "    neighbors = deepcopy(training_data[:k])\n",
    "    for i in range(k, len(training_data)):\n",
    "        for j in range(len(neighbors)):\n",
    "            if \"mahalanobis\" in str(distance_type): #If the distance is mahalanobis\n",
    "                covMatrix = np.cov(training_data[:4], bias=True)\n",
    "                first_distance = distance_type(training_data[i][:iris_location], data_point[:iris_location], covMatrix)\n",
    "                second_distance = distance_type(neighbors[j][:iris_location], data_point[:iris_location], covMatrix)\n",
    "                if first_distance < second_distance:\n",
    "                    neighbors[j] = deepcopy(training_data[i])\n",
    "                    break\n",
    "            else: #If the distance is euclidean or cosine\n",
    "                first_distance = distance_type(training_data[i][:iris_location], data_point[:iris_location])\n",
    "                second_distance = distance_type(neighbors[j][:iris_location], data_point[:iris_location])\n",
    "                if first_distance < second_distance:\n",
    "                    neighbors[j] = deepcopy(training_data[i])\n",
    "                    break\n",
    "    return neighbors\n",
    "\n",
    "#Get the performance metrics \n",
    "def evaluate(k,training_data, testSet, distance_type):\n",
    "    setosa = Setosa()\n",
    "    versicolor = Versicolor()\n",
    "    virginica = Virginica()\n",
    "    for data_point in testSet:\n",
    "        knn_value = k_nearest_neighbor(k, training_data, data_point, distance_type)\n",
    "        class_value = count_neighbors_knn(knn_value)\n",
    "        if class_value == data_point[iris_location]: #True values\n",
    "            if class_value == versicolor.integer_value:\n",
    "                setosa.true_negatives += 1\n",
    "                versicolor.true_positives += 1\n",
    "                virginica.true_negatives += 1\n",
    "            if class_value == setosa.integer_value: \n",
    "                setosa.true_positives += 1\n",
    "                versicolor.true_negatives += 1\n",
    "                virginica.true_negatives+= 1\n",
    "            if class_value == virginica.integer_value:\n",
    "                setosa.true_negatives += 1\n",
    "                versicolor.true_negatives += 1\n",
    "                virginica.true_positives += 1\n",
    "        else: #False values\n",
    "            if class_value == virginica.integer_value:\n",
    "                virginica.false_positives += 1\n",
    "                if data_point[iris_location] == setosa.integer_value:\n",
    "                    setosa.false_negatives += 1\n",
    "                    versicolor.true_negatives += 1\n",
    "                else:\n",
    "                    setosa.true_negatives += 1\n",
    "                    versicolor.false_negatives += 1   \n",
    "            if class_value == setosa.integer_value:\n",
    "                setosa.false_positives += 1\n",
    "                if data_point[iris_location] == versicolor.integer_value:\n",
    "                    versicolor.false_negatives += 1\n",
    "                    virginica.true_negatives += 1\n",
    "                else:\n",
    "                    versicolor.true_negatives += 1\n",
    "                    virginica.false_negatives += 1     \n",
    "            if class_value == versicolor.integer_value:\n",
    "                versicolor.false_positives += 1\n",
    "                if data_point[iris_location] == setosa.integer_value:\n",
    "                    setosa.false_negatives += 1\n",
    "                    virginica.true_negatives += 1\n",
    "                else:\n",
    "                    setosa.true_negatives += 1\n",
    "                    virginica.false_negatives += 1\n",
    "    #Print performance for each iris\n",
    "    setosa.performance()\n",
    "    versicolor.performance()\n",
    "    virginica.performance()\n",
    "    #Print the Macro Averaged Values\n",
    "    print(\"Macro-averaged Accuracy: \",  (setosa.accuracy() + versicolor.accuracy() + virginica.accuracy())/3)\n",
    "    print(\"Macro-averaged Precision: \", (setosa.precision() + versicolor.precision() + virginica.precision())/3)\n",
    "    print(\"Macro-averaged Recall: \",    (setosa.recall() + versicolor.recall() + virginica.recall())/3)\n",
    "    print(\"Macro-averaged F1score: \",   (setosa.f1score() + versicolor.f1score() + virginica.f1score())/3)\n",
    "    return (setosa, versicolor, virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 7 distance_type = cosine\n",
      "--------------------------------------------\n",
      "------------- Initiate Fold ----------------\n",
      "--------------------------------------------\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Macro-averaged Accuracy:  1.0\n",
      "Macro-averaged Precision:  1.0\n",
      "Macro-averaged Recall:  1.0\n",
      "Macro-averaged F1score:  1.0\n",
      "--------------------------------------------\n",
      "-------------- End Fold 0 --------------\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "------------- Initiate Fold ----------------\n",
      "--------------------------------------------\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Macro-averaged Accuracy:  1.0\n",
      "Macro-averaged Precision:  1.0\n",
      "Macro-averaged Recall:  1.0\n",
      "Macro-averaged F1score:  1.0\n",
      "--------------------------------------------\n",
      "-------------- End Fold 1 --------------\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "------------- Initiate Fold ----------------\n",
      "--------------------------------------------\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  0.8571428571428571\n",
      "Precision:  1.0\n",
      "F1 Score:  0.923076923076923\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  1.0\n",
      "Precision:  0.9\n",
      "F1 Score:  0.9473684210526316\n",
      "Macro-averaged Accuracy:  0.9722222222222223\n",
      "Macro-averaged Precision:  0.9666666666666667\n",
      "Macro-averaged Recall:  0.9523809523809524\n",
      "Macro-averaged F1score:  0.9568151147098515\n",
      "--------------------------------------------\n",
      "-------------- End Fold 2 --------------\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "------------- Initiate Fold ----------------\n",
      "--------------------------------------------\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  0.8333333333333334\n",
      "Precision:  1.0\n",
      "F1 Score:  0.9090909090909091\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  1.0\n",
      "Precision:  0.875\n",
      "F1 Score:  0.9333333333333333\n",
      "Macro-averaged Accuracy:  0.9722222222222223\n",
      "Macro-averaged Precision:  0.9583333333333334\n",
      "Macro-averaged Recall:  0.9444444444444445\n",
      "Macro-averaged F1score:  0.9474747474747476\n",
      "--------------------------------------------\n",
      "-------------- End Fold 3 --------------\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "------------- Initiate Fold ----------------\n",
      "--------------------------------------------\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  0.9090909090909091\n",
      "Precision:  1.0\n",
      "F1 Score:  0.9523809523809523\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  0.9583333333333334\n",
      "Recall:  1.0\n",
      "Precision:  0.8571428571428571\n",
      "F1 Score:  0.923076923076923\n",
      "Macro-averaged Accuracy:  0.9722222222222223\n",
      "Macro-averaged Precision:  0.9523809523809524\n",
      "Macro-averaged Recall:  0.9696969696969697\n",
      "Macro-averaged F1score:  0.9584859584859585\n",
      "--------------------------------------------\n",
      "-------------- End Fold 4 --------------\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------\n",
      "---------------- Results -------------------\n",
      "--------------------------------------------\n",
      "\n",
      "\n",
      "Iris type:  Iris-setosa\n",
      "Accuracy:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "F1 Score:  1.0\n",
      "Iris type:  Iris-versicolor\n",
      "Accuracy:  0.9333333333333333\n",
      "Recall:  0.8461538461538461\n",
      "Precision:  1.0\n",
      "F1 Score:  0.9166666666666666\n",
      "Iris type:  Iris-virginica\n",
      "Accuracy:  0.9333333333333333\n",
      "Recall:  1.0\n",
      "Precision:  0.75\n",
      "F1 Score:  0.8571428571428571\n",
      "Macro-averaged Accuracy:  0.9555555555555556\n",
      "Macro-averaged Precision:  0.9166666666666666\n",
      "Macro-averaged Recall:  0.9487179487179488\n",
      "Macro-averaged F1score:  0.9246031746031745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.Setosa at 0x7f1dd0939630>,\n",
       " <__main__.Versicolor at 0x7f1dd0939550>,\n",
       " <__main__.Virginica at 0x7f1dd091ef98>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.training_data\n",
    "testing_data = data.testing_data\n",
    "\n",
    "k = 7 #Change k as desired\n",
    "distance_type = distance.cosine #Change to desired distance function (distance.euclidean, distance.mahalanobis, or distance.cosine)\n",
    "\n",
    "print(\"K =\", k, \"distance_type =\", distance_type.__name__)\n",
    "crossValidation(k, distance_type) #Perform cross validation\n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"---------------- Results -------------------\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"\\n\")\n",
    "evaluate(k, training_data, testing_data, distance_type) #Evaluate data using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
